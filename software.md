[TOC]

# Software components

## Testbed access using ALH protocol

The testbed can be operated remotely through the LOG-a-TEC web portal. The user can select a cluster of VESNAs and configure them to perform sensing and/or transmission. As a result, the testbed is able to support sensing only experiments, transmission only experiments and also transmission based on sensing results. The LOG-a-TEC web portal also uses the GRASS-RaPlaT tool in order to (i) provide the virtual experiment planning via simulation in order to ascertain the best setup before the actual execution in the testbed as well as (ii) support the postprocessing and visualization of experimentation results.

The Log-a-tec testbed consists of several software components as described in the following sections.

### The management network

This section focuses on user access to the VESNA-based testbed and the technologies behind it.

The wireless management network between nodes is based on a proprietary extension to the IEEE 802.15.4 standard. It is a multihop network, which means that any node is able to communicate with any other node in the cluster, even if it is outside of its direct wireless range.

For the purpose of communication between sensor network and the server located at JSI (infrastructure side) we developed a new protocol (see figure below), which was inspired by the HTTP protocol and is simple enough for fast implementation on VESNA nodes. The protocol defines two types of requests, **GET** and **POST**, which are understood by every VESNA node. **GET** requests are used for "safe" requests which do not change the state of the system and **POST** for "unsafe" requests which change the state of the system. The response from a node to these requests is considered to be in binary format and handled accordingly, although general responses are in text format and only the spectrum sensing data is in binary format. Every response ends with the sequence **OK\r\n** to indicate the end of the response.

<img alt="Overview of a typical ALH request" src="img/Resource_access_protocol.png" />

The protocol includes simple and efficient error handling mechanism. There are two types of errors defined. The first is **JUNK-INPUT**, which is the more common situation when the resource name is mistyped and the parser on the node does not recognize it. After this response the parser on the node expects five new lines, which resets the parser. Only after that the resource can be accessed again. The second type of error is **CORRUPTED-DATA**, used when cyclic redundancy check (CRC) check did not succeed thus we can conclude that the error happened somewhere on the line between the infrastructure and the gateway. The last situation will occur with very low probability.

The protocol is designed as a client-server protocol. In our case the servers are sensor nodes and the client is the server on the infrastructure side. Before we can access the resources, the gateway has to establish a connection with the infrastructure side. This is done by establishing a secure SSL encrypted socket with the server. The gateway has an Ethernet module embedded on the expansion board which is used to connect the gateway to the Internet. The Ethernet module is configured to get the IP address from DHCP server and then automatically tries to set up an encrypted SSL socket with one of the SSL servers listening on a specific port located on the infrastructure side. Once the connection has been established one could access any resource (sensor, radio module, etc.) or procedure on any of the nodes. Procedures pre-prepared on the nodes include Remote reprogramming, start spectrum sensing, collect spectrum data, configure nodes as transmitters, configure frequency band, etc. Below a simplified schematic of the VESNA-based testbed is provided.

<img alt="Simplified schematic of a VESNA-based testbed" src="img/Logatec-schematic.png" style="width: 593px; height: 157px; " />

### Testbed access through the web portal

The web app, shown in the figure below, is split in two parts. The right hand side of the graphical user interface (GUI) includes a map where one can observe locations of the nodes and based on the color code distinct between their role in the network (e.g. gateway, ISM band sensing node, TV band sensing node, etc.). The left hand side of GUI is used for the interaction between the user and the testbed. Features in this part of the web app include:

 * **Choosing one of the available clusters**: either at the JSI campus or in Logatec city. Each cluster needs its own SSL server listening on the infrastructure side and by changing the cluster we make a switch to a different SSL server.
 * **Experiment description**: The experiment can be described in a simple text file in which we specify the **GET** and **POST** requests which form our experiment. The commands are separated by an empty line.
 * **Logging support**: All the requests and responses are stored in the request-response log file, where the spectrum sensing data is also collected in the format that corresponds to the CREW common data format.
 * **GET and POST request fields**: The web app also provides an option to send a single manually configured **GET** or **POST** request to the sensor network.
 * **Remote reprogramming support**: For reprogramming the nodes there is an option to select a binary file from a user's local environment and upload it to the server where a special script, written to send the file to the gateway, cuts the file into packets of 512 bytes. Each packet gets a header of 4 bytes containing the serial number of the packet and the footer of 4 bytes with the CRC of the packet. The finished packet is 520 bytes long and gets transferred to the gateway which forwards the packet to the selected end node. The ZigBee packets were extended by an additional layer which can handle packets of this size. The packets are stored on the SD card of the node which is divided into several slots; each slot is able to store one firmware image. After the transfer is complete the node is set to boot the firmware from the requested SD card slot and then rebooted. After a reboot the new firmware is loaded in the flash and started.
 * **Reset SSL connection button**: The web app GUI features also a safety button to reset the system in case of unexpected events that may be caused by bugs or errors in the communication links.

<img alt="" src="img/Logatec_web_portal.png" />

### Testbed access through the exposed HTTP API

As indicated above, the alternative way to access the LOG-a-TEC testbed, mainly supported for the advanced users and developers, is by calling the HTTP API. The call to the API has to meet the specified form for GET and POST requests:

 * https://crn.log-a-tec.eu/communicator?cluster=&quot;port&quot;&amp;method=get&amp;resource=&quot;resource&quot;
 * https://crn.log-a-tec.eu/communicator?cluster=&quot;port&quot;&amp;method=post&amp;resource=&quot;resource&quot;&amp;content=&quot;content&quot;

To make a **GET** or **POST** request we have to make a call to handler called "communicator", which is located on the web server on the LOG-a-TEC infrastructure with the domain name **crn.log-a-tec.eu**. The call is made over secure HTTPS encrypted socket requiring authentication and has to include the following parameters:

 * **The cluster**: This corresponds to the SSL port which the cluster gateway is connected to. The JSI cluster is connected to the port 9501, the Logatec industrial zone cluster to 10001 and the Logatec city center to 10002.
 * **The method**: The method can be either GET or POST.
 * **Resource**: The last parameter in the case of **GET** request is the resource. This corresponds to the resource name located on the target node from one of the clusters.
 * **Content**: The POST request includes also content where we specify the reconfiguration parameters for the nodes.

All the requests that do not meet the specified form are rejected.

The portal can be accessed from <a href="http://www.log-a-tec.eu/">www.log-a-tec.eu</a>, where authentication is necessary to be able to enter. For now the authentication parameters can be added only manually for interested experimenters whereas an automated subscription system with scheduler for the experimenters is under development.

## Testbed access using 6LoWPAN

One of the main demands for LOG-aTEC from external experimenterd was related to the improvement of the low speed of the wireless management network through which the testbed is accessed and controlled. In order to take this into account for the new generation of the testbed that uses the same hardware for completely different embedded software, we first identified the use cases that need to be accommodated by testbeds in general and designed, implemented and performed an initial evaluation of the testbed. The full work is reported in a joint conference paper [51] with open access external experimenters from a Slovenian SME Xlab, who contributed part of the reported solution and was particularly interested in the evaluation of different (re)programming and (re)configuration approaches. 
1 Use cases and required functionality*
We identify two generic use cases for testbeds consisting of constrained devices such as sensor nodes: the monitoring use case and the experimentation use case. the monitoring use case refers to sensor based testbeds that enable monitoring of some phenomena such as energy consumption, humidity, temperature, motion, sound, gases, etc. These kinds of testbeds are typically used by researchers to automatically acquire some data about the phenomena under study. Examples of such testbeds are SmartSantander and CitySense. The experimentation use case refers to sensor based testbeds that support the development of new communication and networking technology by enabling experimentation with new algorithms and protocols. Motelab, TWIST and LOG-a-TEC are examples of such testbeds.
In spite of this division in two major groups, from the point of view of the wireless management network, these testbeds have a set of common functionalities.
1 Need for software upgrades*
From the perspective of software upgrades, we identify three types of required updates: OS/firmware upgrades, driver updates and application updates. OS/firmware upgrades are expected to occur when new versions of these software are released or when a major flaw is discovered and needs immediate fixing. The frequency of these upgrades is expected to be of 3-4 per year at most for both use cases. From the perspective of the size of the code to be transfered over the air to the nodes of the testbed, these upgrades tend to be large.
The driver updates are also expected to be required at most few times per year for the monitoring setupsand for most instances of the experimentation setups. However, for experimental setups that involve MAC layer experiments, the need for upgrades might be more frequent. In many cases, these upgrades can be achieved using dynamic linking, thus avoiding the need for realizing an OS/firmware upgrade. In such cases, the file sent to the nodes of the testbed is relatively small compared to the full OS/firmware image.
The expected application updates vary a lot across testbeds. The more flexible and generic the testbed is, the higher the number of expected application updates. These updates are best performed using dynamic linking and in most cases their expected size is relatively small. Performing a full OS/firmware upload for each application tends to be uneconomical.
2 Need for data collection*
Testbeds used as the monitoring setups require sensor measurement data collection while the ones used as the experimentation setups require the collection of the experimental results. Here we distinguish non-time critical data collection and time-critical data collection. When the data collection is time critical, the measured phenomenon or the experimental results have to be sent to the consumer within a small predefined time period from when they were produced and can also be referred to as (near-)real time data collection. This kind of data collection is encountered in sense-act type of systems that base their actuating decision on the sensed value. When the data collection is not time critical, it is typically saved locally on the node and transmitted all at once in batch mode. This collection mechanism is found in scenarios where the data is being post processed.
We also distinguish reliable and unreliable data collection. In the first case, the loss of the measurement data is undesired while is the second case loss of data is not considered a major issue.
3 Need for remote reconfiguration and control*
Remote reconfiguration is a desired feature for both setups. For the monitoring setup, the user of the testbed might want to change the sampling rate of the sensor or might want to change the size of the buffer that stores the measurements. For the experimentation setup, the user might vary several parameters such as the frequency at which packets are sent, the number of retransmissions, transmitting power, receive channel filter bandwidth, carrier sense indicator etc. In some cases, using remote reconfiguration, the entire experiment can be remotely reconfigured. For instance, using run-time reconfiguration, the entire protocol stack can be reconfigured without flashing the node. Using a fully modular implementation such as CRime, an experiment that uses a gossip based algorithm for sending data can be easily reconfigured to use another type of algorithm.
Remote control is a desired feature for sense-act scenarios that can also appear in both setups. For instance, in a monitoring setup, a light can be dimmed in response to the sensed values of luminance and presence. In an experimentation setup, a node can be controlled to start a transmission after another node sensed a free channel.
2 Design, implementation and initial evaluation of the LOG-a-TEC cognitive networking testbed*
1 Design choices *
When building a new testbed from scratch, one is faced with selecting a desired hardware platform and a supported operating system. Heterogeneous testbeds may chose several different such platforms. The use cases and functionality, as well as the considerations with respect to reprogramming, reconfiguration, speed and reliability should be taken into account when selecting the hardware and OS. For instance, with some OSes it will be impossible to support dynamic linking and/or run time reconfiguration. The resulting combination of hardware/OS selected needs to be evaluated and optimized similar to the example provided in this section.
When upgrading an already existing testbed, there may be already existing constraints on the choice of hardware and software. For instance, the starting points for the extension of the already existing LOG-a-TEC testbed was the VESNA sensor node and the ProtoStack tool. The VESNA platform is already being used in the existing testbed for spectrum sensing and cognitive radio experimentation and is the supporting block of most of our research activities. The ProtoStack tool has been developed to support modular protocol development that would enable easy experimentation with multi-hop routing algorithms using also learned link characteristic for the routing decision - thus enabling cognitive networking experimentation. As ProtoStack relies on the Contiki OS, the extension has to use this operating system.
Starting with these constraints, answers for the following three main issues have to be found:
How to enable two wireless - experimental and management - networks running in parallel on VESNA with Contiki (subsection 2)?
How should experiment reconfiguration, control and software upgrade be performed (subsection 3)?
Which transceiver should be used for the management network in order to achieve the best possible throughput (subsection 1)?

### Dual-stack Contiki on VESNA

VESNA sensor nodes deployed in the 6LowPAN testbed have two independent transcievers: Texas Instruments CC1101 (868 MHz) and Atmel AT86RF230 (2.4 GHz). Hardware supports the use of both transceivers at the same time. So, while the hardware set-up already supports dual stack (one for management and one for experimentation), a solution for a dual-stack OS had to be developed.

Contiki OS includes two protocol stacks, one based on uIPv6 that can be configured as 6LowPAN/uIPv6/UDP/CoAP and the second protocol stack which is custom and is referred to as Rime. 6LowPAN assumes a IEEE802.15.4 compatible transceiver and since only the Atmel transceivers comply to this, the most natural decision was to consider the Atmel transceivers for the management network and the TI transceivers for the experimental network. However, in the normal release of Contiki OS the two stacks cannot run in parallel but only one at a time.  This required extension/adaptation of the Contiki OS to support dual stack operation. The original Contiki OS code uses compile-time defined network layers. Some layers are used by both Rime and uIP at the same time (see framer_nullmac in the figure below), so we modified the networking code to explicitly pass information about which network stack the current packet belongs to. It should be noted that in a single stack Contiki, Rime uses 2 bytes for node network address, while uIP requires 8 bytes. To keep Rime packet small, thus maintaining the low power consumption of the Rime stack, we modified Contiki to permit different network address size for Rime and uIPv6 packets respectively.

Finally, we integrated the new, Composable Rime network stack that enables reconfigurable protocol stacks in the Contiki OS and configured the operating system to support the 6LowPAN based management network and the CRime based experimental network in parallel as depicted in the figure below.

![Dual-stack Contiki on VESNA](img/dualstack.png)

### Software upgrades, reconfiguration and control

Software upgrades require a bootloader running on the VESNA platform and a large image to be sent to the node over the management network. In the case under investigation, the full image of the monolithic dual stack is in the range of 150 kB as shown in Table . This image corresponds to a particular application (i.e. single experiment) and needs to be changed should another application be needed (i.e. flash the node).
Table  Transfer size.

In order to support minor updates of drivers and applications, we used dynamic loading through the Contiki ELF (Executable and Linkable Format) loader module. Our main interest was to enable dynamically reprogrammable network stacks. In other words, we investigated the possibility of transferring new stack compositions, each representing a new experiment. This requires splitting the application into two parts.
The first part, called core, is responsible for loading the minimal Contiki OS with added ELF loader functionality. This part of the node firmware is not changed during reprogramming. It is responsible for downloading the ELF application through the management network and to dynamically link it with the core OS.
To implement it, we had to include the base Contiki image with uIPv6, TCP/UDP and CoAP, also support for:
SD card driver and Contiki Coffee FS. 
Utility application to receive ELF file from network, and write it to a file.
ELF loader (generic and CPU architecture specific part) to do actual ELF file relocation.
Symbol table stores addresses and names of all core OS functions, which might be called by the ELF application.
The second part is the ELF application. The application calls functions exported by the core OS, and is compiled as a standard ELF file. When splitting the previous monolithic dual stack image into core OS (with uIP management network) and ELF application (with CRime experimental network) we have the option to leave some code parts, used only by CRime, in the core OS. In particular, we decided to leave the TI CC radio driver in the core OS. As that particular piece of code is already stable, we expect it will not require frequent updates. This resulted in about 50% smaller ELF application file.
The automatically generated symbol table contains the address and the name of each function in the core. Many of them are not even supposed to be used by the application (low level hardware initialization, static functions, ARM CMSIS library functions). Thus we minimized the core OS image size by excluding unneeded function entries from the symbol table.
We looked at the size of the file to be transferred to the nodes over the air for the very simple hello-world application and for a more complex trickle stack. The size of the hello-world ELF file is 1.7 kB while the size for the trickle ELF file is 11 kB as listed in Table . The trickle ELF application is small compared to the full OS image, but it still does have a significant overhead due to the ELF file metadata.
This observation led us to look at run-time reconfiguration options, where all the CRime modules are loaded on the node using a monolithic system image and then a stack composition message, which describes and configures the experiment, is sent. We used an un-optimized JSON format for the configuration message whose size can vary between 1.6 kB for a simple experiment to 8 kB for a more complex experiment as shown in Table . The code required for parsing the JSON and generating the experiment added additional 7.5 kB to the size of the system image.
1 Transceiver selection*
As explained in Sect. Error: Reference source not found the selected hardware platform supports operation of the management and experimentation networks in two ISM bands, depending on the choice of transceivers to be soldered on the SNE-ISMTV boards used on VESNA, and this subsection deals with the selection of the most suitable transceiver for the management network. The candidate transceivers supporting the management network are two Atmel transceivers: AT86RF230 (2.4 GHz) and AT86RF212 (868 MHz). The first step in evaluating these transceivers was to determine the three operating regions, effective, clear and transitional, referring to regions with the packet success rate above 90%, below 10% and with highly varying value between these boundaries, respectively [41].
The experiment was carried out on a 55 meter corridor of a long building where several WiFi access points are also active. Figure  plots the three regions empirically determined in our experiments for the AT86RF230 (2.4 GHz) transceiver. The tests show that the effective region goes up to 22 m in the line of sight conditions (no obstacles on the corridor). Additionally, we performed experiments to understand how the throughput is affected by the packet rate as shown in Figure . The results show that rates exceeding 70 packets per second lead to packet losses. 
The plots for the AT86RF212 (868 MHz) transceiver are similar, with the effective region ending at 28 m and the optimal application rate being also at 70 packets per second..

Figure  Reception success rate as a function of distance for the AR86RF230 (2.4 GHz) transceiver.

Figure  Reception success rate as a function of application packet rate for the AT86RF230 (2.4 GHz) transceiver.
After determining the three regions for the two transceivers under consideration, we looked at the application transfer rates and various settings that influence these. For instance, by using the header compression enabled by 6LoWPAN, the application payload can be increased thus maximizing the data rate. The CoAP client was mimicking reprogramming functionality by sending large files for reprogramming the nodes running CoAP server and data collection functionality by requesting (randomly generated) data from the nodes (see Figure ). The CoAP clients are located on a wired IPv4/IPv6 network, then use a gateway towards the border router which has a wireless management interface for the nodes. The links between the nodes and the border router were within the effective regions, hence reliable.
 
Figure  Experimental set-up for the initial evaluation.
We performed two different types of experiments, upload and download for two different sets of radio transceivers Atmel AT86RF212 (Table ) and AT86RF230 (Table ). Each type of the experiment had five different steps and with each step we were increasing the size of the data (i.e. file) to be transmitted between 128 and 256000 bytes. To get more reliable results we repeated each step 10 times and then we calculated the average throughput value. With respect to the upload and download we performed 100 measurements per radio transceiver. From the results in Table  and Table , it can be seen that AT86RF230 is achieving higher data throughput and the links are more stable. 
In our evaluation we only considered packets that contain payload data, avoiding acknowledgments messages that are sent for each packet and that are not relevant for the application data rate. We decided to use HC01 and HC02 compression for 6LoWPAN because if the CoAP client is accessing the testbed from a different network subnet, the IPv6 address will not be fully compressed in any case. Packet fragmentation was disabled. MAC header compression was not used, because it is supported only by the AT86RF212 MAC. As a note, there are several configurations and tunings that can be performed with such an evaluation. Configurations in the Contiki OS, the used drivers and the point from which the client is accessing the node influence the final performance of the wireless management network. 
Table  Evaluation of AT86RF212.

Table  Evaluation of AT86RF230.

Tables Table  and Table  are summarizing results where 64 bytes of application payload has been used. It can be seen that transferring 128000 bytes (a bit less than a full system image from Table ), 68 seconds are needed when using AT86RF230 and 177 seconds when using AT86RF212. For the dynamic loading of a simple application or its run-time reconfiguration using a non-optimal JSON format, less than a second is needed with AT86RF230 and under 2 seconds with AT86RF212. Our initial experiments showed that the AT86RF230 transceiver is more suitable if speed is the only selection criterion. Further tests and evaluations with respect to other criteria are underway.

## GRASS-RaPlaT for experiment planning and visualization of measurements

In order to help experimenter in setting parameters of the experiment, the radio propagation tool <a href="http://www-e6.ijs.si/en/software/grass-raplat">GRASS-RaPlaT</a> is included in JSI Outdoor VESNA-based testbed. GRASS-RaPlaT is an open-source radio planning tool developed at Jo≈æef Stefan Institute as an add-on to the open source Geographical Information Systems (GIS) GRASS. GRASS operates over raster and vector data and includes methods for image processing and display. It comprises over 350 modules for processing, analysis and visualization of geographical data. The core modules and libraries are written in the C programming language. For large projects, processing may be automated by using a scripting language such as Phyton. MySQL, PostgreSQL and DBF database engines are currently supported by GRASS and can be used for storing the data table. In addition, GRASS maps and modules may be imported into other GIS software packages, e.g. Q-GIS.

RaPlaT is a set of modules for a number of channel models, a module for sectorization according to given antenna patterns, a module for calculating and storing the complete radio network coverage data, and a number of supporting modules, e.g. for adapting input data and analyzing simulation results. Thus GRASS-RaPlaT is a powerful tool for designing, analyzing and presenting single node or radio network coverage.

The role of the GRASS-RaPlaT in LOG-a-TEC testbed is (i) to provide support in experiment planning via simulation in order to ascertain the best setup before the actual execution in the testbed and (ii) to support the postprocessing and visualization of experimentation results. An experiment is configured via a web interface and the results of the experiment are also accessible via the web interface. A web server requests the required computation by simply issuing a Linux command with corresponding parameters. This command, which is actually a script, establishes the necessary GRASS environment and executes callbacks of GRASS-RaPlaT or other commands.

The web interface allows configuring nodes either as a transmitter or a receiver. If a particular node is not configured as a transmitter or a receiver, it is assumed as a non-active for the experiment. The main variable parameters for a transmitter are its transmission power and frequency. To provide support in experiment planning, the following preset simulations of radio coverage by GRASS-RaPlaT (&ldquo;virtual experiments&rdquo;) are available: (i) transmission radio coverage estimation, (ii) transmission range estimation (interference area) of the nodes, (iii) estimation of the signal level at the specified receiver locations for all active transmitters, (iv) estimation of the coverage area of all active transmitters and (v) hidden node detection simulation. In the experiments aimed at determining the location of the hidden node based on the measurements obtained from the testbed, GRASS-RaPlaT provides support for the post-processing and visualization of experimentation results and thus calculates the hidden node interference area.

<img alt="" src="img/Grass-Raplat-UHF_Simulation_0.png" />
